import os
from typing import List

# LangChain Core components
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# Vector Store & Embeddings
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI

# Retrievers for Hybrid Search
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever

if "GOOGLE_API_KEY" not in os.environ:
    raise RuntimeError("Please set the GOOGLE_API_KEY in your environment variables first.")

# è¨­å®š Embedding model
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/text-embedding-004"
)

# è¨­å®š Vector Store (Chroma)
CHROMA_PATH = "./chroma_db_eng"
if not os.path.exists(CHROMA_PATH):
    raise RuntimeError(f"âŒ Vector DB not found at {CHROMA_PATH}! Please run your ingest script first.")

vector_store = Chroma(
    persist_directory=CHROMA_PATH,
    embedding_function=embeddings,
    collection_name="demo_rag"
)

# Hybrid Search
print("æ­£åœ¨åˆå§‹åŒ–æ··åˆæª¢ç´¢ç³»çµ± (Vector + BM25)...")

existing_data = vector_store.get() 
existing_texts = existing_data['documents']
existing_metadatas = existing_data['metadatas']

if not existing_texts:
    raise RuntimeError("Chroma DB is empty! Cannot initialize BM25.")

# å°‡å–å‡ºçš„æ–‡å­—è½‰å› Document ç‰©ä»¶
doc_objects = [
    Document(page_content=text, metadata=meta) 
    for text, meta in zip(existing_texts, existing_metadatas)
]

# å»ºç«‹ BM25 Retriever (é—œéµå­—æœå°‹)
bm25_retriever = BM25Retriever.from_documents(
    documents=doc_objects
)
bm25_retriever.k = 5

# å»ºç«‹ Vector Retriever (æœ€åŸå§‹çš„èªæ„æœå°‹)
chroma_retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 5}
)

# çµåˆå…©è€…æˆç‚º Ensemble Retriever (Hybrid Search)
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, chroma_retriever],
    weights=[0.5, 0.5] # é€šå¸¸é—œéµå­—æœå°‹ (BM25) åœ¨ç²¾ç¢ºåè©ä¸Šå¾ˆå¼·ï¼Œæ¬Šé‡å¯ä»¥è¨­ç‚º 0.5 æˆ– 0.4
)

# è¨­å®š LLM èˆ‡ Prompt
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", 
    temperature=0.3, 
)

system_prompt = (
    "You are a professional AI assistant. Please answer the user's questions based on the [context information] provided below."
    "You must respond in English."
    "If you cannot find the answer in the provided context, please state that you do not know and do not fabricate an answer."
    "\n\n"
    "[Context Information]:\n"
    "{context}"
)

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}"),
    ]
)

# RAG Chain
question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(ensemble_retriever, question_answer_chain)

if __name__ == "__main__":
    print("\n=========================================")
    print("ğŸ¤– Gemini RAG System Ready (Hybrid Search)")
    print("=========================================\n")

    while True:
        try:
            query = input("è«‹è¼¸å…¥å•é¡Œ (è¼¸å…¥ 'exit' é›¢é–‹) > ")
            if query.lower() in ["exit", "quit"]:
                break
            
            if not query.strip():
                continue

            print("\næ­£åœ¨æ€è€ƒä¸­...\n")
            
            # åŸ·è¡Œ Chain
            response = rag_chain.invoke({"input": query})

            print(f"A: {response['answer']}")
            print("-" * 60)

        except Exception as e:
            print(f"Error: {e}")