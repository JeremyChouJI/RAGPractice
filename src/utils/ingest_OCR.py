import os

from langchain_community.document_loaders import DirectoryLoader
from langchain_community.document_loaders import UnstructuredPDFLoader
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings

def ingest_data_unstructured():
    print("ğŸš€ Starting ingestion with Unstructured (OCR Mode)...")
    
    folder_path = "./data_source"
    
    if not os.path.exists(folder_path):
        print("âŒ Data directory not found.")
        return

    print(f"ğŸ“‚ Loading PDFs from {folder_path}...")
    print("â³ This process will be SLOW because it's doing OCR layout analysis.")

    # --- æ ¸å¿ƒè¨­å®š ---
    loader = DirectoryLoader(
        path=folder_path,
        glob="*.pdf",
        loader_cls=UnstructuredPDFLoader,
        loader_kwargs={
            "mode": "elements",           # è§£æç‚ºç¨ç«‹å…ƒç´ 
            "strategy": "hi_res",         # å•Ÿç”¨é«˜è§£æåº¦ OCR
            "languages": ["eng"]
        }
    )
    
    try:
        raw_docs = loader.load()
    except Exception as e:
        print(f"âŒ Error: {e}")
        print("ğŸ’¡ Hint: If the error mentions 'tesseract', check your PATH environment variable.")
        return
    # ----------------
    
    if not raw_docs:
        print("âš ï¸ No documents loaded.")
        return

    print(f"ğŸ“„ Loaded {len(raw_docs)} elements.")
    
    # é è¦½ä¸€ä¸‹è¾¨è­˜çµæœï¼Œç¢ºèªä¸­æ–‡æ˜¯å¦æ­£å¸¸
    if len(raw_docs) > 0:
        preview_text = raw_docs[0].page_content[:100].replace('\n', '')
        print(f"ğŸ” Preview: {preview_text}...")

    # åˆ‡åˆ†èˆ‡å„²å­˜ (ç¶­æŒåŸæ¨£)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=100,
        separators=["\n\n", "\n", " ", ""]
    )
    chunks = text_splitter.split_documents(raw_docs)
    print(f"ğŸ“¦ Split into {len(chunks)} chunks.")
    # --- ã€æ ¸å¿ƒä¿®æ”¹é–‹å§‹ã€‘ ---
    print("ğŸ§¹ Cleaning complex metadata for ChromaDB...")
    # éæ¿¾æ‰ ChromaDB ä¸æ”¯æ´çš„è¤‡é›œ Metadata (å¦‚åº§æ¨™è³‡è¨Š)
    # é€™ä¸€æ­¥æœƒæŠŠ dict æˆ– list é¡å‹çš„ metadata åˆªæ‰ï¼Œåªç•™ç°¡å–®å‹åˆ¥
    chunks = filter_complex_metadata(chunks)
    # --- ã€æ ¸å¿ƒä¿®æ”¹çµæŸã€‘ ---

    if "GOOGLE_API_KEY" not in os.environ:
        print("âš ï¸ Warning: GOOGLE_API_KEY not set.")
    else:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
        
        if os.path.exists("./chroma_db_eng"):
            print("âš ï¸  Appending to existing DB...")

        vector_store = Chroma.from_documents(
            documents=chunks,
            embedding=embeddings,
            collection_name="demo_rag",
            persist_directory="./chroma_db_eng",
        )
        print("âœ… Ingestion complete! Data saved.")

if __name__ == "__main__":
    ingest_data_unstructured()